{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dan/miniconda3/envs/pyspicalc/lib/python3.12/site-packages/mne/externals/tempita/__init__.py:35: DeprecationWarning: 'cgi' is deprecated and slated for removal in Python 3.13\n",
      "  import cgi\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from mne import make_fixed_length_epochs\n",
    "\n",
    "\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import dill\n",
    "from pyspi.calculator import Calculator\n",
    "import time\n",
    "from natsort import natsorted\n",
    "import warnings\n",
    "import mne\n",
    "import pandas as pd\n",
    "\n",
    "def norm(y):\n",
    "    # normalize signal\n",
    "    q25, q50, q75 = np.percentile(y, [25, 50, 75])\n",
    "    whisker_lim = 1.5 * (q75 - q25)\n",
    "    high_lim = q75 + whisker_lim\n",
    "    low_lim = q25 - whisker_lim\n",
    "    # fig, ax = plt.subplots(1, 2)\n",
    "    # ax[0].plot(y)\n",
    "    # ax[0].axhline(high_lim, color=\"r\")\n",
    "    # ax[0].axhline(low_lim, color=\"r\")\n",
    "    # ax[0].axhline(q50, color=\"g\")\n",
    "    m = np.mean(y[(y <= high_lim) & (y >= low_lim)])\n",
    "    s = np.std(y[(y <= high_lim) & (y >= low_lim)])\n",
    "    # ax[0].axhline(m, color=\"b\")\n",
    "    z = (y - m) / s\n",
    "    # ax[1].plot(z)\n",
    "    # ax[1].axhline(5, color=\"r\")\n",
    "    # ax[1].axhline(-5, color=\"r\")\n",
    "    # plt.show()\n",
    "\n",
    "    return z\n",
    "\n",
    "def read_edf(path, drop_non_eeg=True, normalize=False, drop_EEG_Prefix=True, preload=False):\n",
    "    path = str(path)\n",
    "    non_eeg = [\n",
    "        \"DC1\",\n",
    "        \"Baseline\",\n",
    "        \"ECG\",\n",
    "        \"EKG\",\n",
    "        \"EMG\",\n",
    "        \"MD/Pic\",\n",
    "        \"MD\",\n",
    "        \"Pic\",\n",
    "        \"Mic\",\n",
    "        \"Mic-0\",\n",
    "        \"Mic-1\",\n",
    "        \"Mic-2\",\n",
    "        \"Mic-3\",\n",
    "        \"Mic-4\",\n",
    "        \"Mic-5\",\n",
    "        \"Motor\",\n",
    "        \"Music\",\n",
    "        \"Noise\",\n",
    "        \"Picture\",\n",
    "        \"Story\",\n",
    "        \"ECG ECG\",\n",
    "        \"EEG ECG\",\n",
    "        \"Pt Mic\",\n",
    "        \"MD Mic\",\n",
    "        \"PT Mic\",\n",
    "        \"Hand Motor\",\n",
    "        \"ECG EKG\",\n",
    "        \"EKG ECG\",\n",
    "        \"Hand\",\n",
    "        \"EDF Annotations\",\n",
    "    ]\n",
    "\n",
    "    if normalize:\n",
    "        # data has to be preloaded to normalize\n",
    "        preload = True\n",
    "\n",
    "\n",
    "    if drop_non_eeg:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            mne_raw = mne.io.read_raw_edf(path, preload=preload, verbose=False, exclude=non_eeg)\n",
    "        sEEG_picks = mne.pick_types(mne_raw.info, eeg=True, exclude=[])\n",
    "    else:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "            mne_raw = mne.io.read_raw_edf(path, preload=preload, verbose=False)\n",
    "        sEEG_picks = np.arange(len(mne_raw.ch_names))\n",
    "\n",
    "    if drop_EEG_Prefix:\n",
    "        mne_raw.rename_channels(lambda x: x.replace(\"EEG \", \"\"))\n",
    "        # replace spaces with nothing\n",
    "        mne_raw.rename_channels(lambda x: x.replace(\" \", \"\"))\n",
    "\n",
    "        # some electrodes have spaces, strip whitespace\n",
    "        mne_raw.rename_channels(lambda x: x.replace(' ','').strip())\n",
    "\n",
    "    # monkey patch(s) for patient 98 and 82\n",
    "    # replace \"W-A\" with \"W~A\" because dash is delimiter for bipolar channels\n",
    "    mne_raw.rename_channels(lambda x: x.replace(\"-\", \"~\"))\n",
    "    if '082_' in path:\n",
    "        mne_raw.rename_channels(lambda x: x.replace(\"ECGA'11\", \"A'11\")) # one of the files is mislabeled as ECG\n",
    "\n",
    "\n",
    "\n",
    "    chNames = np.array(mne_raw.ch_names)[sEEG_picks]\n",
    "    primes = [x for x in chNames if \"'\" in x]\n",
    "    non_primes = [x for x in chNames if \"'\" not in x]\n",
    "    prime_n = len(primes)\n",
    "    non_prime_n = len(non_primes)\n",
    "    primes = list(natsorted(primes))\n",
    "    non_primes = list(natsorted(non_primes))\n",
    "\n",
    "    if len(non_primes) > 0:\n",
    "        non_primes.extend(primes)\n",
    "        chNames = non_primes\n",
    "    else:\n",
    "        chNames = primes\n",
    "    if len(chNames) != prime_n+non_prime_n:\n",
    "        raise ValueError(\"Something went wrong with the channel names\")\n",
    "\n",
    "    z = mne_raw.pick(chNames).reorder_channels(chNames)\n",
    "        \n",
    "    if normalize:\n",
    "        return z.apply_function(norm)\n",
    "    else:\n",
    "        return z\n",
    "\n",
    "\n",
    "mapping_path = \"/media/dan/Big/manuiscript_0001_hfo_rates/data/FULL_composite_patient_info.csv\"  \n",
    "ilae_path = \"/media/dan/Big/manuiscript_0001_hfo_rates/ravi_hfo_numbers~N59+v03.csv\"\n",
    "bad_channels_path = \"/media/dan/Big/manuiscript_0001_hfo_rates/data/bad_ch_review.xlsx\"\n",
    "edf_path = \"/media/dan/Data/data/iEEG/raw_ieeg/baseline_patients/baseline_edfs\"\n",
    "output_path = \"/media/dan/Data/git/network_miner/connectivity/output\"\n",
    "\n",
    "pid_source_path = \"/media/dan/Big/manuiscript_0001_hfo_rates/ravi_hfo_numbers~N59+v03.csv\"\n",
    "\n",
    "\n",
    "dur_msec = 500\n",
    "dur_sec = dur_msec / 1000\n",
    "overlap_msec = 1/2048\n",
    "overlap_sec = overlap_msec / 1000\n",
    "\n",
    "\n",
    "# get metadata\n",
    "mappings = pd.read_csv(mapping_path)\n",
    "ilae = pd.read_csv(ilae_path)\n",
    "bad_channels = pd.read_excel(bad_channels_path)\n",
    "bad_channels[\"use\"] = bad_channels[\"use\"].fillna(1)\n",
    "bad_channels[\"use2\"] = bad_channels[\"use2\"].fillna(1)\n",
    "bad_channels[\"use\"] = bad_channels[\"use\"].astype(bool)\n",
    "bad_channels[\"use2\"] = bad_channels[\"use2\"].astype(bool)\n",
    "\n",
    "# OR bad_channel columns\n",
    "bad_channels[\"bad_channel\"] = ~(bad_channels[\"use\"] & bad_channels[\"use2\"])\n",
    "\n",
    "# for each patient in mappings, find the corresponding ilae number. The patient may not be in the ilae dataset but has a designation of seizureFree or not.\n",
    "# if the patient is not in the ilae dataset, then use the seizureFree column to determine the ilae number where -1 is seizureFree and 100 is not seizureFree\n",
    "ilae_numbers = {}\n",
    "for pid in mappings[\"pid\"].unique():\n",
    "    if pid in ilae[\"patient\"].values:\n",
    "        ilae_numbers[pid] = ilae[ilae[\"patient\"] == pid][\"ilae\"].values[0]\n",
    "    else:\n",
    "        if mappings[mappings[\"pid\"] == pid][\"seizureFree\"].values[0] == True:\n",
    "            ilae_numbers[pid] = -1\n",
    "        else:\n",
    "            ilae_numbers[pid] = 100\n",
    "\n",
    "# now we have a dictionary of ilae numbers for each patient. Fill in the mappings dataframe with these numbers which has multiple rows for each patient\n",
    "ilae_list = []\n",
    "for pid in mappings[\"pid\"]:\n",
    "    ilae_list.append(ilae_numbers[pid])\n",
    "mappings[\"ilae\"] = ilae_list\n",
    "\n",
    "\n",
    "# Perform the merge as before\n",
    "mappings = mappings.merge(\n",
    "    bad_channels[['pid', 'ch', 'bad_channel']],\n",
    "    left_on=['pid', 'electrode'],\n",
    "    right_on=['pid', 'ch'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop the 'ch' column if needed\n",
    "mappings = mappings.drop(columns=['ch'])\n",
    "\n",
    "# Fill NaN values in 'bad_channel' with 0\n",
    "mappings['bad_channel'] = mappings['bad_channel'].fillna(0)\n",
    "\n",
    "\n",
    "# find all cells with \"\" or \"nan\" and mark them as bad_channels (assuming outside of brain)\n",
    "mappings.loc[(mappings[\"miccai\"].isna() & mappings[\"aal\"].isna()), \"bad_channel\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all edf files from folder\n",
    "edf_path = \"/media/dan/Data/data/iEEG/raw_ieeg/baseline_patients/baseline_edfs\"\n",
    "edfs = [os.path.join(edf_path,f) for f in list(sorted(os.listdir(edf_path)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "digit_count = 10\n",
    "\n",
    "output_path = \"/media/dan/Big/network_mining/calculations/sixrun/calculations/npyfiles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sfreq \u001b[38;5;241m*\u001b[39m dur_sec) \u001b[38;5;241m*\u001b[39m i\n\u001b[1;32m     52\u001b[0m end_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(sfreq \u001b[38;5;241m*\u001b[39m dur_sec) \u001b[38;5;241m*\u001b[39m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpid\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m03\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_epoch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mstart_idx\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdigit_count\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mend_idx\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdigit_count\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyspicalc/lib/python3.12/site-packages/numpy/lib/_npyio_impl.py:574\u001b[0m, in \u001b[0;36msave\u001b[0;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m    573\u001b[0m     arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(arr)\n\u001b[0;32m--> 574\u001b[0m     \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfix_imports\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfix_imports\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyspicalc/lib/python3.12/site-packages/numpy/lib/format.py:755\u001b[0m, in \u001b[0;36mwrite_array\u001b[0;34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m--> 755\u001b[0m         \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    757\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m numpy\u001b[38;5;241m.\u001b[39mnditer(\n\u001b[1;32m    758\u001b[0m                 array, flags\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexternal_loop\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbuffered\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzerosize_ok\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    759\u001b[0m                 buffersize\u001b[38;5;241m=\u001b[39mbuffersize, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "\n",
    "# make output path\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "for edf in tqdm(edfs):\n",
    "\n",
    "    pid = int(os.path.basename(edf).split(\"_\")[0])\n",
    "\n",
    "    pid_mappings = mappings[mappings[\"pid\"] == pid]\n",
    "\n",
    "    raw = read_edf(edf, preload=True)\n",
    "\n",
    "    # drop bad channels\n",
    "    try:\n",
    "        raw = raw.drop_channels(pid_mappings[pid_mappings[\"bad_channel\"] == 1][\"electrode\"].values)\n",
    "    except:\n",
    "        bc = pid_mappings[pid_mappings[\"bad_channel\"] == 1][\"electrode\"]\n",
    "        for b in bc:\n",
    "            try:\n",
    "                raw = raw.drop_channels(b)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # save channel names in order of raw to a csv\n",
    "    pd.DataFrame(raw.ch_names).to_csv(os.path.join(output_path, f\"{pid:03}_chnames.csv\"))\n",
    "    \n",
    "    # filter\n",
    "    sfreq = raw.info[\"sfreq\"]\n",
    "    nyq_freq = raw.info[\"sfreq\"] // 2 - 1\n",
    "    line_freq = 60\n",
    "    l_freq = 0.5\n",
    "    h_freq = min(nyq_freq, 300)\n",
    "    raw = raw.filter(l_freq=l_freq, h_freq=h_freq)\n",
    "    freqs = np.arange(line_freq, max(h_freq, nyq_freq), line_freq)\n",
    "    raw = raw.notch_filter(freqs=freqs, method=\"fir\")\n",
    "\n",
    "    # average reference\n",
    "    raw = raw.set_eeg_reference(ref_channels=\"average\", projection=False, verbose=False)\n",
    "\n",
    "    data = raw.get_data()\n",
    "\n",
    "\n",
    "    # non overlapping epochs\n",
    "    dur_sec = .5\n",
    "    overlap_sec = 0\n",
    "    epochs = make_fixed_length_epochs(raw, duration=dur_sec,overlap=overlap_sec, preload=True)\n",
    "    epochs = epochs.get_data()\n",
    "\n",
    "\n",
    "    for i, e in enumerate(tqdm(epochs)):\n",
    "        start_idx = int(sfreq * dur_sec) * i\n",
    "        end_idx = int(sfreq * dur_sec) * (i+1)\n",
    "        np.save(os.path.join(output_path, f\"{pid:03}_epoch_{start_idx:0{digit_count}}-{end_idx:0{digit_count}}.npy\"), e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the YAML file location\n",
    "yaml_file = os.path.join(output_path,\"run_config.yaml\")\n",
    "\n",
    "# remove the file if it already exists\n",
    "if os.path.exists(yaml_file):\n",
    "    os.remove(yaml_file)\n",
    "\n",
    "# ps -> rows = processes; columns = time pts.\n",
    "dim_order = \"ps\"\n",
    "\n",
    "\n",
    "import glob\n",
    "files = list(sorted(list(glob.glob(os.path.join(output_path, \"*.npy\")))))\n",
    "\n",
    "for f in sorted(files): # start 1 minute in only use first 5 seconds\n",
    "    # get the epoch number\n",
    "    i = os.path.basename(f).split(\"_\")[-1].split(\".\")[0]\n",
    "\n",
    "    pid = os.path.basename(f).split(\"_\")[0]\n",
    "    # define template string and fill in variables\n",
    "    \n",
    "    lbl = f\"{pid}_epoch_{i}\"\n",
    "    path = os.path.join(output_path, lbl)\n",
    "    yaml_string = \"{{file: {file}.npy, name: {key}, dim_order: {dim_order}, labels: [{key}]}}\\n\"\n",
    "    yaml_string_formatted = f\"- {yaml_string.format(file=path, key=lbl, dim_order=dim_order)}\"\n",
    "\n",
    "    # append line to file\n",
    "    with open(yaml_file, \"a\") as f:\n",
    "        f.write(yaml_string_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "doc = os.path.join(output_path, \"run_config.yaml\")\n",
    "with open(doc) as d:\n",
    "    yf = yaml.load(d,Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now to run:\n",
    "\n",
    "cd /home/dan/data/connectivity/pyspi_testing\n",
    "\n",
    "conda activate pyspicalc\n",
    "\n",
    "python distribute_jobs.py --data_dir \"/home/dan/data/connectivity/pyspi_testing/sixrun/calculations/data\" --calc_file_name calc.pkl --compute_file pyspi_compute.py --template_pbs_file template.pbs --sample_yaml \"run_config.yaml\" --conda_env pyspicalc --queue workq --walltime_hrs 1 --cpu 1 --mem 6 --table_only --pyspi_config \"/home/dan/data/connectivity/pyspi_testing/sixrun/sixmeasures.yaml\" --overwrite_pkl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "watch -n 2 \"qstat -q\"\n",
    "\n",
    "\n",
    "#other\n",
    "qsub -J 1-600 -l select=1:ncpus=1:mem=10mb -- /bin/sleep 1\n",
    "\n",
    "\n",
    "\n",
    "qdel $(qselect -u $(whoami))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspicalc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

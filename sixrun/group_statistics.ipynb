{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import dill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Patients:   0%|          | 0/72 [00:41<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# Function to write results to HDF5\n",
    "def save_to_hdf5(path, data, file_path):\n",
    "    if len(data) == 0:\n",
    "        return\n",
    "    with h5py.File(file_path, \"a\") as hdf5_file:\n",
    "        if path not in hdf5_file:\n",
    "            hdf5_file.create_dataset(path, data=data, maxshape=(None,), compression=\"gzip\")\n",
    "        else:\n",
    "            dataset = hdf5_file[path]\n",
    "            dataset.resize(dataset.shape[0] + data.shape[0], axis=0)\n",
    "            dataset[-data.shape[0]:] = data\n",
    "\n",
    "def get_idxs(idxs, soz_idx):\n",
    "    soz_soz = []\n",
    "    soz_non = []\n",
    "    non_soz = []\n",
    "    non_non = []\n",
    "    for x, y in zip(idxs[0], idxs[1]):\n",
    "        if x in soz_idx and y in soz_idx:\n",
    "            soz_soz.append((x, y))\n",
    "        elif x in soz_idx or y in soz_idx:\n",
    "            if x in soz_idx:\n",
    "                soz_non.append((x, y))\n",
    "            else:\n",
    "                non_soz.append((x, y))\n",
    "        else:\n",
    "            non_non.append((x, y))\n",
    "    return np.array(soz_soz), np.array(soz_non), np.array(non_soz), np.array(non_non)\n",
    "\n",
    "def safe_slice_and_flatten(measure, idx_array):\n",
    "    if len(idx_array) == 0:\n",
    "        return np.array([])  # Return empty array if no indices\n",
    "    return measure[:, idx_array[:, 0], idx_array[:, 1]].flatten()\n",
    "\n",
    "output_path = \"/media/dan/Data/data/calculations\"\n",
    "mapping_path = \"/media/dan/Big/manuiscript_0001_hfo_rates/data/FULL_composite_patient_info.csv\"  \n",
    "ilae_path = \"/media/dan/Big/manuiscript_0001_hfo_rates/ravi_hfo_numbers~N59+v03.csv\"\n",
    "calculation_path = \"/media/dan/Big/network_mining/calculations/sixrun/calculations/six_run\"\n",
    "\n",
    "\n",
    "mappings = pd.read_csv(mapping_path)\n",
    "ilae = pd.read_csv(ilae_path)\n",
    "# for each patient in mappings, find the corresponding ilae number. The patient may not be in the ilae dataset but has a designation of seizureFree or not.\n",
    "# if the patient is not in the ilae dataset, then use the seizureFree column to determine the ilae number where -1 is seizureFree and 100 is not seizureFree\n",
    "ilae_numbers = {}\n",
    "for p in mappings[\"pid\"].unique():\n",
    "    if p in ilae[\"patient\"].values:\n",
    "        ilae_numbers[p] = ilae[ilae[\"patient\"] == p][\"ilae\"].values[0]\n",
    "    else:\n",
    "        if mappings[mappings[\"pid\"] == p][\"seizureFree\"].values[0] == True:\n",
    "            ilae_numbers[p] = -1\n",
    "        else:\n",
    "            ilae_numbers[p] = 100\n",
    "\n",
    "# now we have a dictionary of ilae numbers for each patient. Fill in the mappings dataframe with these numbers which has multiple rows for each patient\n",
    "ilae_list = []\n",
    "for p in mappings[\"pid\"]:\n",
    "    ilae_list.append(ilae_numbers[p])\n",
    "mappings[\"ilae\"] = ilae_list\n",
    "\n",
    "\n",
    "files = list(sorted(os.listdir(calculation_path)))\n",
    "pids = list(sorted(set([int(f.split(\"_\")[0]) for f in files])))\n",
    "\n",
    "# read the first file from the first patient to get the calculation names. make sure file has \"epoch\" in the name\n",
    "first_epoch_file = [f for f in files if \"epoch\" in f][0]\n",
    "\n",
    "with open(os.path.join(calculation_path, first_epoch_file, 'calc.pkl'), \"rb\") as f:\n",
    "    calc = dill.load(f)\n",
    "columns = calc.columns.levels[0].unique().values    \n",
    "\n",
    "for pid in tqdm(pids, desc=\"Patients\", leave=True):\n",
    "    pid_files = list(sorted([f for f in files if f.startswith(f\"{pid:03}\")]))\n",
    "    chnames_idx = pid_files.index(f\"{pid:03}_chnames.csv\")\n",
    "    chnames = pd.read_csv(os.path.join(calculation_path, pid_files[chnames_idx]))['0'].values\n",
    "    pid_files.pop(chnames_idx)\n",
    "\n",
    "    pid_mappings = mappings[mappings[\"pid\"] == pid]\n",
    "    pid_mappings = pid_mappings[pid_mappings[\"electrode\"].isin(chnames)]\n",
    "    pid_mappings = pid_mappings.set_index(\"electrode\").reindex(chnames).reset_index()\n",
    "\n",
    "    soz_idx = pid_mappings.index[pid_mappings[\"soz\"] == 1].values\n",
    "    ilae_group = pid_mappings[\"ilae\"].iloc[0]\n",
    "\n",
    "    if len(soz_idx) == 0:\n",
    "        continue\n",
    "\n",
    "    data = []\n",
    "    skip = False\n",
    "    for file in pid_files:\n",
    "        with open(os.path.join(calculation_path, file, 'calc.pkl'), \"rb\") as f:\n",
    "            try:\n",
    "                data.append(dill.load(f))\n",
    "            except:\n",
    "                print(f\"Error loading {file}\")\n",
    "                skip = True\n",
    "                break\n",
    "    if skip:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    for col in tqdm(data[0].columns.levels[0].unique(), desc=f\"Columns for {pid}\", leave=False):\n",
    "        if \"gc_gaussian\" not in col:\n",
    "            continue\n",
    "        measure = []\n",
    "        for r in data:\n",
    "            full = r[col].values\n",
    "            measure.append(full)\n",
    "        measure = np.array(measure)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gc_gaussian_k-1_kt-1_l-1_lt-1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(609, 118, 118)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to matlab\n",
    "import scipy.io\n",
    "scipy.io.savemat(f\"{pid}_grangercause.mat\", {\"measure_directed\": measure, \"soz\": pid_mappings[\"soz\"]})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspicalc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
